{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Best Model\n",
    "\n",
    "- input: splitted data\n",
    "- get best parameters for best model\n",
    "- evaluate model\n",
    "- save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def smape(real, predicted):\n",
    "    return 100/len(real) * np.sum(2 * np.abs(predicted - real) / (np.abs(real) + np.abs(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(data_splitted_path_file, param_grid, random_seed=0, save_in=None):\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Read Splitted Data\n",
    "    with open(data_splitted_path_file, 'rb') as f:\n",
    "        splitted_data = pickle.load(f)\n",
    "\n",
    "    # Get X and y\n",
    "    X = pd.concat([splitted_data[i]['X_train'] for i in splitted_data.keys()])\n",
    "    X = X[~X.index.duplicated(keep='first')]\n",
    "\n",
    "    y = pd.concat([splitted_data[i]['y_train'] for i in splitted_data.keys()])\n",
    "    y = y[~y.index.duplicated(keep='first')]\n",
    "    \n",
    "    map_x_index = {i:j for i,j in zip(X.index, list(X.reset_index().index))}\n",
    "    map_y_index = {i:j for i,j in zip( y.index, list(y.reset_index().index))}\n",
    "    \n",
    "    cv = [(np.array([map_x_index[j] for j in splitted_data[i]['X_train'].index]),\n",
    "           np.array([map_x_index[j] for j in splitted_data[i]['X_test'].index]))\n",
    "          for i in splitted_data.keys()]    \n",
    "\n",
    "    # Create a based model\n",
    "    rf = RandomForestRegressor(random_state=random_seed)\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=rf,\n",
    "                               param_grid=param_grid, \n",
    "                               cv=cv,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=2)\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"Best Parameters are:\", grid_search.best_params_)\n",
    "    \n",
    "    if save_in is not None:\n",
    "        directory = os.path.dirname(save_in)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "        with open(save_in, 'wb') as f:\n",
    "            pickle.dump(grid_search.best_estimator_, f)\n",
    "        \n",
    "        with open(os.path.join(directory, \"X.pkl\"), 'wb') as f:\n",
    "            pickle.dump(X, f)\n",
    "        \n",
    "        with open(os.path.join(directory, \"y.pkl\"), 'wb') as f:\n",
    "            pickle.dump(y, f)\n",
    "    \n",
    "    return grid_search, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(splitted_data, best_grid):\n",
    "    \n",
    "    metrics = {}\n",
    "    for i_fold in splitted_data.keys():\n",
    "        y_true = splitted_data[i_fold]['y_test']\n",
    "        y_pred = best_grid.predict(splitted_data[i_fold]['X_test'])\n",
    "\n",
    "        y_true_train = splitted_data[i_fold]['y_train']\n",
    "        y_pred_train = best_grid.predict(splitted_data[i_fold]['X_train'])\n",
    "\n",
    "        mse_train = mean_squared_error(y_true_train, y_pred_train)\n",
    "        smape_train = smape(y_true_train, y_pred_train)\n",
    "        mape_train = mape(y_true_train, y_pred_train)\n",
    "\n",
    "        mse_ = mean_squared_error(y_true, y_pred)\n",
    "        smape_ = smape(y_true, y_pred)\n",
    "        mape_ = mape(y_true, y_pred)\n",
    "        \n",
    "        metrics[i_fold] = {\n",
    "                            \"MSE\":mse_, \"SMAPE\":smape_, \"MAPE\":mape_,\n",
    "                            \"MSE-train\":mse_train, \"SMAPE-train\":smape_train, \"MAPE-train\":mape_train\n",
    "                          }\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO MAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best Parameters are: {'bootstrap': True, 'criterion': 'squared_error', 'max_depth': 6, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "data_splitted_path_file = \"/Users/lalachaimaenaciri/PycharmProjects/SCORE_LOW_HIGH_CAPSADSTR_INTENSITY/data/ready/splitted_data.pkl\"               \n",
    "save_model_in = \"/Users/lalachaimaenaciri/PycharmProjects/SCORE_LOW_HIGH_CAPSADSTR_INTENSITY/models/rf_model.pkl\"               \n",
    "\n",
    "\n",
    "param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': [2, 4, 6],\n",
    "        'max_features': [1, 3, 5],\n",
    "        'min_samples_leaf': [1],\n",
    "        'min_samples_split': [2, 4],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': [\"squared_error\"]\n",
    "    }\n",
    "\n",
    "grid_search, X, y = get_best_model(data_splitted_path_file=data_splitted_path_file,\n",
    "               param_grid=param_grid, save_in=save_model_in\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'MSE': 0.027290032251858335,\n",
       "  'SMAPE': 7.949226912581428,\n",
       "  'MAPE': 10.656085356589275,\n",
       "  'MSE-train': 0.017253068307872946,\n",
       "  'SMAPE-train': 4.884852852841844,\n",
       "  'MAPE-train': 5.029730787659908},\n",
       " 1: {'MSE': 0.01851205693081037,\n",
       "  'SMAPE': 5.416938641452723,\n",
       "  'MAPE': 5.636899769291746,\n",
       "  'MSE-train': 0.02164205596839693,\n",
       "  'SMAPE-train': 6.150996988406194,\n",
       "  'MAPE-train': 7.53932358130867},\n",
       " 2: {'MSE': 0.01599407968493552,\n",
       "  'SMAPE': 4.35276706423096,\n",
       "  'MAPE': 4.422561806028068,\n",
       "  'MSE-train': 0.02290104459133435,\n",
       "  'SMAPE-train': 6.683082777017076,\n",
       "  'MAPE-train': 8.146492562940512}}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrcis = evaluate(splitted_data, grid_search.best_estimator_)\n",
    "metrcis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAPE 6.905182310636363\n"
     ]
    }
   ],
   "source": [
    "# Mean MAPE\n",
    "print(\"Train MAPE\", np.mean([metrcis[i][\"MAPE\"] for i in splitted_data.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
